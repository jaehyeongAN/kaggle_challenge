{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "test_id = test['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 1: 결측값을 의미하는 '-1'의 개수\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "\n",
    "# 파생변수 2: 이진 변수의 합\n",
    "bin_features = [c for c in train.columns if 'bin' in c]\n",
    "train['bin_sum'] = train[bin_features].sum(axis=1)\n",
    "test['bin_sum'] = test[bin_features].sum(axis=1)\n",
    "\n",
    "# 파생변수 3: target encoding\n",
    "features = ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_12_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_11_cat', 'ps_ind_01', 'ps_ind_03', 'ps_ind_15', 'ps_car_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of LightGBM\n",
    "num_boost_round = 10000\n",
    "params = {\n",
    "    'objective':'binary',\n",
    "    'boosting_type':'gbdt',\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':15,\n",
    "    'max_bin':256,\n",
    "    'feature_fraction':0.6,\n",
    "    'verbosity':0,\n",
    "    'drop_rate':0.1,\n",
    "    'is_unbalance':False,\n",
    "    'max_drop':50,\n",
    "    'min_child_samples':10,\n",
    "    'min_child_weight':150,\n",
    "    'min_split_gain':0,\n",
    "    'subsample':0.9,\n",
    "    'seed':2018\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_leaves, max_bin, min_child_samples와 같은 설정값으로 모델의 복잡도를 조절\n",
    "features_fraction, subsample, max_drop 등의 설정값으로 과적합을 방지\n",
    "\n",
    "참고\n",
    "- https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst\n",
    "- https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters-Tuning.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 교차 검증 평가\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "kf = kfold.split(train, train_label)\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))\n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "\n",
    "for i, (train_fold, validate) in enumerate(kf):\n",
    "    # split train/validate\n",
    "    X_train, X_validate, label_train, label_validate = train.iloc[train_fold, :], train.iloc[validate,:], train_label[train_fold], train_label[validate]\n",
    "    \n",
    "    # target encoding\n",
    "    for feature in features:\n",
    "        # 훈련 데이터에서 feature 고유값별로 타겟 변수의 평균을 구함 \n",
    "        map_dic = pd.DataFrame([X_train[feature], label_train]).T.groupby(feature).agg('mean')\n",
    "        map_dic = map_dic.to_dict()['target']\n",
    "        \n",
    "        X_train[feature+'_target_enc'] = X_train[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        X_validate[feature+'_target_enc'] = X_validate[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        test[feature+'_target_enc'] = test[feature].apply(lambda x: map_dic.get(x, 0))\n",
    "        \n",
    "    dtrain = lgbm.Dataset(X_train, label_train)\n",
    "    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "    \n",
    "    # evalerror()를 통해 검증 데이터에 대한 정규화 Gini계수 점수를 기준으로 한 최적의 트리 개수\n",
    "    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, \n",
    "                    verbose_eval=100, early_stopping_rounds=100)\n",
    "    best_trees.append(bst.best_iteration)\n",
    "    \n",
    "    # predict\n",
    "    cv_pred += bst.predict(test, num_iteration=bst.best_iteration)\n",
    "    cv_train[validate] += bst.predict(X_validate)\n",
    "    \n",
    "    # score\n",
    "    score = Gini(label_validate, cv_train[validate])\n",
    "    print(score)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "cv_pred /= NFOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
